---
layout: post
title:  "Cats & Dogs Binary Classification"
categories: MachineLearning
tags: DL ML America
author: Chester Cheung
---

* content
{:toc}

### First notebook shows how to train a CNN from scratch.

> Also its my first time to finish one deep learning work myself.

The works are all based on Kaggle platform to have a better operation and are more convinent  to commit and modify. Also this is the general way to do some works about machine learning and deep learning and data science.


[DL of Cats & Dogs Binary Classification](https://www.kaggle.com/chestercheung/dl-of-cats-dogs-binary-classification)

Keras of Tensorflow has a directory-centric api but kaggle kernels cannot write too many files. We read in the images and rescale the values to between 0 and 1. You then make an ImageDataGenerator that preprocesses the data. If you overfit augment the data and add dropout.






The final result of this project is basically above 60 percent. And I'll continue to work on this task to have more understanding of DL model and Keras. 

### Another project work with one partner to solve the sale problem.

[Feature engineering, xgboost](https://www.kaggle.com/chestercheung/freshman-in-feature-engineering)

And the final result of this one is almost about Top 28% , which is not so bad for a freman in feature engineering. 

> **During my works, I've found that there are 2 key points during these works.**

1. Generally, according to CV problem, the first thing to do is image pre-processing, which is transforming images into RGB dataframes. And also, we simply change the data into 3 dimensions' problem. 

2. If we train data directly without any process, the accuracy of the model is pretty low. So we'll do some thing to improve the accuracy. Basically, we can have some operations for images to swift, move or something like that.

3. Finally, our work have got great progress in the last commitment.

